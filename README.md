Task 2: AI Feedback System - Production Deployment Guide
ğŸ“‹ Overview
A production-ready, two-dashboard AI feedback system deployed on Vercel with:

User Dashboard: Collect 1-5 star ratings and reviews, get AI-generated responses

Admin Dashboard: View all submissions with AI summaries and recommended actions in real-time

Backend: Next.js API routes (serverless) with full LLM integration

Database: PostgreSQL (Neon) for persistent storage

LLM: OpenAI GPT-3.5-turbo for all summarization and responses

ğŸ—ï¸ Architecture
text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Vercel (Next.js)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Frontend:                                              â”‚
â”‚  â”œâ”€ / (User Dashboard) - Form + AI Response Display    â”‚
â”‚  â””â”€ /admin (Admin Dashboard) - Live Submissions List   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Backend (API Routes - Serverless):                    â”‚
â”‚  â”œâ”€ POST /api/submissions - Submit review + Generate  â”‚
â”‚  â””â”€ GET /api/submissions-list - Fetch all submissions â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LLM Integration (Server-side only):                   â”‚
â”‚  â”œâ”€ Generate summary from review                       â”‚
â”‚  â”œâ”€ Generate recommended action                        â”‚
â”‚  â””â”€ Generate user-facing response                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  PostgreSQL (Neon)      â”‚
  â”‚  - Persistent storage   â”‚
  â”‚  - Auto-scaling         â”‚
  â”‚  - Serverless           â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ Quick Start
Prerequisites
Node.js 18+ and npm

GitHub account

Vercel account (free)

Neon PostgreSQL account (free)

OpenAI API key

Step 1: Clone and Setup Locally
bash
# Clone repository
git clone <your-repo>
cd feedback-ai-system

# Install dependencies
npm install

# Create .env.local
cp .env.local.example .env.local
Step 2: Setup PostgreSQL (Neon)
Go to neon.tech and create a free account

Create a new project named "feedback_db"

Copy the connection string: postgresql://user:password@pg.neon.tech/feedback_db

Add to .env.local:

text
DATABASE_URL=postgresql://user:password@pg.neon.tech/feedback_db
Initialize database:

bash
npm run migrate
Step 3: Setup OpenAI API
Go to platform.openai.com

Create API key

Add to .env.local:

text
OPENAI_API_KEY=sk-...your-key...
Step 4: Deploy to Vercel
Option A: Git Integration (Recommended)
Push code to GitHub

Go to vercel.com/new

Import your GitHub repository

Set environment variables in Vercel dashboard:

DATABASE_URL - Your Neon connection string

OPENAI_API_KEY - Your OpenAI API key

Deploy

Option B: Vercel CLI
bash
# Install Vercel CLI
npm i -g vercel

# Login and deploy
vercel --prod

# Add environment variables when prompted
ğŸ“Š API Documentation
POST /api/submissions
Request:

json
{
  "rating": 4,
  "review": "Great product, but delivery was slow"
}
Response:

json
{
  "success": true,
  "data": {
    "id": 1,
    "rating": 4,
    "review": "Great product, but delivery was slow",
    "userResponse": "Thank you for your feedback! We're glad you liked the product and we'll work on improving delivery times.",
    "createdAt": "2024-01-06T14:23:00.000Z",
    "status": "processed"
  }
}
Error Response:

json
{
  "success": false,
  "error": "Rating must be between 1 and 5"
}
GET /api/submissions-list
Query Parameters:

limit (optional): Number of results (default: 50)

offset (optional): Pagination offset (default: 0)

rating (optional): Filter by rating (1-5, or 'all')

Response:

json
{
  "success": true,
  "total": 42,
  "data": [
    {
      "id": 42,
      "rating": 5,
      "review": "Excellent service!",
      "aiSummary": "Customer was very satisfied with service quality.",
      "recommendedAction": "Share positive feedback on social media",
      "userResponse": "Thank you for the wonderful feedback!",
      "createdAt": "2024-01-06T14:20:00.000Z",
      "status": "processed"
    }
  ]
}
ğŸ›¡ï¸ Error Handling
The system gracefully handles:

Empty Reviews
Submission allowed (rating still required)

AI generates fallback messages

Example: "Thank you for your submission..."

Long Reviews
Automatically truncated to 500 characters for LLM

Full review stored in database

No user-facing errors

LLM Failures
If OpenAI API is down, graceful fallbacks applied

User sees success message with default response

Admin dashboard shows status = "processed" with fallback summary

No broken forms or 500 errors

Database Failures
Connection pooling with retry logic

Returns 500 with clear error message

Client sees "Failed to process submission"

Network Issues
Client-side fetch timeout handling

SWR library auto-retries on connection loss

Admin dashboard continues with cached data

ğŸ“± Dashboard Features
User Dashboard (/)
â­ 1-5 star rating selector

ğŸ“ Text area for reviews (optional, 0-2000 chars)

âœ“ Success state with AI-generated response

âŒ Error handling with retry ability

ğŸ“± Fully responsive (mobile-first)

Admin Dashboard (/admin)
ğŸ”„ Auto-refresh: 3s, 5s, 10s intervals, or manual

ğŸ“Š Real-time stats: Total submissions, average rating

ğŸ“ˆ Rating distribution: Visual bar chart

ğŸ·ï¸ Filter by rating: Quick filter buttons

ğŸ“‹ Submission list: Cards showing:

User rating and timestamp

Original review text

AI-generated summary

Recommended next action

Processing status

ğŸ¨ Clean, professional UI with smooth animations

ğŸ”§ Configuration
Environment Variables
text
# Required
DATABASE_URL=postgresql://...
OPENAI_API_KEY=sk-...

# Optional
NEXT_PUBLIC_API_BASE=https://your-domain.vercel.app
NODE_ENV=production
Database Schema
sql
CREATE TABLE feedback_submissions (
  id SERIAL PRIMARY KEY,
  rating INTEGER NOT NULL CHECK (rating >= 1 AND rating <= 5),
  review TEXT NOT NULL,
  ai_summary TEXT,
  recommended_action TEXT,
  user_response TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  status VARCHAR(20) DEFAULT 'pending'
);

CREATE INDEX idx_created_at ON feedback_submissions(created_at DESC);
CREATE INDEX idx_rating ON feedback_submissions(rating);
ğŸŒ Deployment Links
After deployment, you'll have:

User Dashboard:

text
https://your-project.vercel.app/
Admin Dashboard:

text
https://your-project.vercel.app/admin
ğŸ“ˆ Cost Estimates
Service	Free Tier	Cost
Vercel	100 GB bandwidth/mo	$0
Neon PostgreSQL	3GB storage, 1GB compute	$0
OpenAI API	N/A	~$0.002 per submission
For 1000 submissions/month: ~$2 OpenAI costs

ğŸ” Security Considerations
âœ… Implemented:

All LLM calls server-side (no API keys in frontend)

Environment variables via Vercel secrets

Input validation on all API endpoints

CORS enabled but permissive (can be tightened)

Database connection pooling

SQL parameterization (no injection risks)

âš ï¸ Limitations:

No authentication on admin dashboard (use VPN/firewall in production)

No rate limiting (implement if public-facing)

No DDOS protection (use Vercel DDoS protection)

ğŸ“‹ Implementation Checklist
 User Dashboard with star rating and review form

 Admin Dashboard with real-time auto-refresh

 Server-side LLM integration (no client-side API calls)

 Persistent PostgreSQL database

 REST API with explicit JSON schemas

 Error handling for empty reviews, long reviews, API failures

 Both dashboards deployed on Vercel

 Auto-refresh with configurable intervals

 Beautiful, responsive UI

 Production-ready code structure

ğŸ§ª Testing
Manual Testing Checklist
User Dashboard:

 Submit feedback with rating and review

 Submit with empty review

 Submit with very long review (2000+ chars)

 Verify AI response appears

 Test on mobile

Admin Dashboard:

 Check auto-refresh works

 Change refresh interval

 Filter by rating

 Verify submission appears after user submission

 Test on mobile

Error Cases:

 Disconnect network, try submission

 Disable JavaScript, verify graceful degradation

 Test with OpenAI API key disabled

ğŸ“ Notes
State Management: React hooks + SWR (no Redux needed)

Styling: CSS Modules (scoped, no conflicts)

Database: Single connection pool shared across API routes

Caching: SWR handles client-side caching with revalidation

Performance: Serverless functions auto-scale on Vercel

ğŸ†˜ Troubleshooting
"DATABASE_URL not found"
Verify .env.local exists in project root

Check Vercel environment variables are set

Restart dev server: npm run dev

"OPENAI_API_KEY invalid"
Check API key is correct at platform.openai.com

Verify key is set in .env.local

Check for accidental spaces in key

"No submissions appearing"
Check database connection: vercel logs --follow

Verify submissions table exists

Check /api/submissions-list endpoint in browser console

"Admin dashboard not auto-refreshing"
Check browser console for fetch errors

Verify API endpoint is accessible

Try manual refresh button

Check SWR refresh interval setting

ğŸ“ Support
For issues:

Check logs: vercel logs --follow

Test endpoint directly: curl https://your-domain/api/submissions-list

Verify database: Connect via Neon console

Check OpenAI status: openai.com/status

Deployment trigger
